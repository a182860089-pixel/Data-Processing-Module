# 数据转换平台 开发计划书

> 目标：在现有 `data_to_md` 基础上，构建一个支持多种数据 → PDF、PDF → Markdown（DeepSeekOCR + MinerU）、图片压缩 WebP，并通过 Celery 实现并发与批量处理的数据转换平台。
>
> 说明：本计划按 **从简单到困难** 的顺序排列，每一项标注了难度和主要风险点，方便逐步实现与迭代。

---

## 阶段 0：现有项目梳理与基础清理（难度：★☆☆☆☆）

**目标**：完全吃透现有 `data_to_md-main` 和 `proc_image/smallimg` 的能力，为后续扩展打好基础。

---

### 阶段 0 实施结果（已完成）

> 本节为阶段 0 实际完成情况的记录，可作为后续阶段的设计依据。

#### 0.1 现有 PDF → Markdown 流程梳理结论

1. **整体流程**
   - 上传 PDF 文件 → 保存到 `storage/uploads/`。
   - 通过 `FileTypeDetector` 判定为 PDF。
   - 由 `PDFAnalyzer` 分析 PDF：页数、大小、文本/图片分布等。
   - 根据分析结果选择处理器：
     - 纯图片：`ImagePDFProcessor`（全部走 OCR）。
     - 图文混排 / 纯文本：`MixedPDFProcessor`（按页判断是否 OCR 或文本提取）。
   - `ImageProcessor` 将 PDF 页面渲染为图片（Base64），调用 DeepSeek OCR 得到 Markdown 片段。
   - `MarkdownGenerator` 负责：
     - 页级内容拼接。
     - 是否插入页码、元数据（由 options 控制）。

2. **并发模型**
   - 使用 `asyncio.Semaphore(max_concurrent_api_calls)` 控制单个 PDF 内页面并发数。
   - 对于每一页：
     - 异步渲染为图片。
     - 异步调用 DeepSeekOCR。
   - 最终使用 `asyncio.gather` 聚合所有页的 `ContentChunk`。

3. **页码与元数据控制**
   - `MarkdownGenerator` 支持：
     - `include_metadata`: 是否在结果中加入 PDF 元信息。
     - `no_pagination_and_metadata`: 为 true 时，不在 Markdown 中插入页码与元数据（更适合直接阅读场景）。
   - 当前实现已预留这两种模式，后续可在 API 级别暴露为更直观的参数名。

#### 0.2 任务管理与 API 流程结论

1. **任务生命周期**
   - `ConversionService` 在开始转换时：
     - 通过 `TaskManager.create_task()` 创建任务，初始状态为 `PENDING`。
     - 更新状态为 `PROCESSING`，开始执行转换。
     - 转换成功后：
       - 将 Markdown 内容写入 `storage/outputs/`。
       - 更新任务为 `COMPLETED`，记录元数据（页数、耗时、文件大小等）。
     - 失败时：
       - 调用 `fail_task()` 标记为 `FAILED` 并记录错误信息。

2. **同步 API 行为**
   - `POST /api/v1/convert`：
     - 直接在请求生命周期内完成上述全部流程。
     - 响应中直接带回 `markdown_content` 和 `task_id`。
   - `GET /api/v1/status/{task_id}`：
     - 从 `TaskManager` 查询任务对象，返回状态与进度字段占位（目前进度更新较简单）。
   - `GET /api/v1/download/{task_id}`：
     - 根据任务记录的 `result_path` 返回文件。

3. **当前存在的改进空间（为后续阶段准备）**
   - 任务状态与进度仅保存在内存，进程重启后会丢失。
   - /convert 接口为同步模式，大文件容易导致客户端超时。
   - 任务进度缺乏细粒度的页面级更新（后续可与 Celery 结合改造）。

#### 0.3 图片压缩脚本梳理结论

1. **核心能力**（来自 `proc_image/smallimg/webp_compress.py`）
   - 支持多种输入格式（jpg/png/tiff/bmp/webp/heic/gif 等）。
   - 自动尝试：
     - EXIF 自动旋转。
     - 转换到 sRGB 色彩空间。
     - 先整数缩放再连续缩放，提升性能与质量。
   - 通过 `quality` 参数控制 WebP 有损压缩质量（0–100）。
   - 支持指定最大宽高（`max_width`/`max_height`），默认 1920×1080。

2. **对未来 API 的启示**
   - 可以在图片压缩 API 中暴露：
     - `quality`（清晰度与体积的平衡）。
     - `max_width` / `max_height`（分辨率约束）。
     - 可选 `target_size_kb`（目标体积），用于二次优化。
   - 底层实现已验证可在 14 寸笔记本屏幕上保证 250KB 左右仍可读，适合作为默认策略。

---

### 任务
1. 梳理现有 PDF → Markdown 流程
   - 阅读并整理：
     - `app/core/converters/pdf/pdf_converter.py`
     - `app/core/converters/pdf/image_pdf_processor.py`
     - `app/core/converters/pdf/mixed_pdf_processor.py`
     - `app/core/common/markdown_generator.py`
   - 输出一份简短设计说明：
     - 如何判断 PDF 类型（IMAGE / MIXED / TEXT）
     - 如何并发处理页面（asyncio + 信号量）
     - Markdown 中是否带页码、是否带元数据的开关逻辑

2. 梳理现有任务管理与API
   - 阅读：
     - `app/services/conversion/conversion_service.py`
     - `app/services/conversion/task_manager.py`
     - `app/api/v1/endpoints/convert.py`
     - `app/api/v1/endpoints/status.py`
   - 画出当前的时序图：上传 → 同步转换 → 返回 Markdown

3. 梳理图片压缩脚本
   - 阅读 `proc_image/smallimg/webp_compress.py`
   - 提炼出：
     - 质量参数（quality）
     - 分辨率限制（max_width / max_height）
     - 适合做 API 暴露的可选参数

**产出**：
- 一份简洁的架构/流程笔记（可写在 `docs/` 或 `开发计划书.md` 后面章节）

**风险 / 难点**：无实质开发，仅阅读与理解，难度最低。

---

## 阶段 1：API 与目录结构规范化（难度：★☆☆☆☆）

**目标**：保证文件结构与 FastAPI / RESTful 最佳实践一致，为后续扩展留出清晰位置。

### 任务
1. 项目结构梳理与小幅调整
   - 确认 `app/api/v1/endpoints` 为唯一对外 REST API 入口
   - 预留好以下文件（如不存在则创建空文件）：
     - `app/api/v1/endpoints/image.py`（图片压缩API）
     - `app/api/v1/endpoints/batch.py`（批量转换API）
   - 保持与 README 中的目录结构一致

2. RESTful 风格统一
   - 资源命名：
     - `/convert` → 视为对「转换任务」资源的创建
     - `/status/{task_id}` → 查询任务资源
     - `/download/{task_id}` → 下载任务结果
   - 统一响应格式：
     - `success`（bool）
     - `data`（dict，可选）
     - `message`（string）
     - `error`（dict，可选）

3. 文档更新
   - 更新 `README.md` 或新增 `docs/api_v1.md`，描述已有接口和即将新增的接口占位。

**风险 / 难点**：
- 主要是命名和风格统一，不涉及复杂逻辑，难度较低。

---

## 阶段 2：图片压缩 WebP API 封装（难度：★★☆☆☆）

**目标**：将现有 `webp_compress.py` 能力封装为 FastAPI API，支持用户自定义压缩参数。

### 任务
1. 抽象图片压缩服务
   - 新建：`app/core/converters/image/webp_compressor.py`
   - 从 `proc_image/smallimg/webp_compress.py` 中抽出核心逻辑：
     - 文件遍历、格式过滤
     - `process_one()` 压缩单张图片
   - 封装为类：
     - 方法：`compress_one(input_path, output_path, quality, max_width, max_height, target_size_kb=None)`

2. 设计图片压缩请求模型
   - 在 `app/models/request.py` 中新增：
     - `ImageCompressOptions`：
       - `quality: int = 90`
       - `max_width: int = 1920`
       - `max_height: int = 1080`
       - `target_size_kb: int | None = 250`

3. 开发图片压缩API
   - 文件：`app/api/v1/endpoints/image.py`
   - 接口：
     - `POST /api/v1/image/compress`
       - 入参：
         - `file: UploadFile`
         - `options: Form(str)`（JSON字符串，可选）
       - 行为：
         - 保存上传图片到 `storage/uploads/images/`
         - 调用 `WebPCompressor` 进行压缩
         - 返回：
           - 输出文件大小、质量参数、下载URL

4. 返回参数可选位置保留
   - options 中预留：`target_size_kb`、`quality_mode` 等未来可扩展字段

**风险 / 难点**：
- 主要是将 CLI 脚本改造为可复用服务，逻辑清晰，难度中等偏低。

---

## 阶段 3：PDF → Markdown 现有功能增强（难度：★★☆☆☆）

**目标**：在现有 DeepSeekOCR 流程上，把「带页码 / 不带页码」、「带元数据 / 不带元数据」等模式整理清晰，保证质量。

### 任务
1. 明确两种 Markdown 输出模式
   - 模式 A：
     - Markdown 中显示内容页码 + 必要元数据
   - 模式 B：
     - 不显示页码，也不显示元数据（适合直接阅读）
   - 在 `ConvertOptions` 中加入：
     - `show_page_number: bool = True`
     - `include_metadata: bool = True`
     - 或统一为 `no_pagination_and_metadata: bool`（与现有代码兼容）

2. 优化表格处理策略（仅简单调整）
   - 记录当前表格处理「好用」的场景与问题
   - 在代码中注释说明：
     - 表格目前策略：对于纯图片页用 OCR，对于带图表的文本页也走 OCR
   - 暂不大改算法，只保证行为稳定可预期

3. 单元测试补齐
   - 针对：
     - 纯图片 PDF
     - 图文混排且包含图表的 PDF
     - 纯文本 PDF
   - 测试点：
     - 是否走 OCR 或文本提取
     - 输出 Markdown 中页码/元数据是否符合选项

**风险 / 难点**：
- 不涉及新引擎，仅在现有逻辑上增强，难度可控。

---

## 阶段 4：MinerU 接入与双引擎封装（难度：★★★☆☆）

**目标**：在 DeepSeekOCR 之外，新增 MinerU 作为第二套 PDF → MD 能力，并抽象出统一的 OCR 引擎接口。

### 任务
1. 设计 OCR 引擎统一接口
   - 新建：`app/services/external/base_ocr_client.py`
   - 抽象：
     - 方法：`async ocr_image(base64_image: str) -> str`
     - 或 `async ocr_pdf(file_path: str) -> str`

2. DeepSeekClient 改造为实现该接口
   - 改造现有 `DeepSeekClient`，让其实现统一接口

3. MinerUClient 实现
   - 新建：`app/services/external/mineru_client.py`
   - 根据 MinerU 的 API / SDK：
     - 完成鉴权、请求、错误处理

4. 在 PDF 处理链中引入引擎选择参数
   - 在 `ConvertOptions` 中增加：
     - `ocr_engine: Literal["deepseek", "mineru", "auto"] = "auto"`
   - 在 `ImagePDFProcessor` / `MixedPDFProcessor` 中，根据 `ocr_engine` 选择对应 client

5. 简单选择策略（不含轮询）
   - `ocr_engine == "deepseek"` → 只用 DeepSeek
   - `ocr_engine == "mineru"` → 只用 MinerU
   - `ocr_engine == "auto"` → 先 DeepSeek，失败时回退 MinerU（简单故障转移）

**风险 / 难点**：
- 对 MinerU 的API/SDK 熟悉程度要求较高
- 错误处理与超时控制要做好，避免影响整个转换流程
- 难度中等。

---

## 阶段 5：OCR 引擎轮询与负载均衡（难度：★★★★☆）

**目标**：在双引擎基础上实现轮询/简单负载均衡，避免某一引擎被打爆，提升稳定性。

### 任务
1. OCRRouter 设计与实现
   - 新建：`app/core/converters/pdf/ocr_router.py`
   - 管理多个 OCRClient：
     - `engines = {"deepseek": DeepSeekClient(), "mineru": MinerUClient()}`
   - 支持策略：
     - `round_robin`：按顺序轮询两个引擎
     - `failover`：主用 A，失败时自动切换到 B
   - 维护基础状态：
     - 引擎连续失败次数
     - 简单的熔断（失败 N 次后短暂熔断）

2. PDF Processor 中集成 OCRRouter
   - 在 `ImagePDFProcessor` / `MixedPDFProcessor` 中：
     - 将直接调用 `DeepSeekClient` 改为通过 `OCRRouter`

3. 配置项增加
   - 在 `config.py` 中新增：
     - `OCR_ROUTING_STRATEGY = round_robin/failover`
     - `OCR_ENGINE_WEIGHTS`（如未来要按权重分流时使用）

4. 日志与监控
   - 在日志中打印：
     - 当前使用的 OCR 引擎
     - 引擎错误统计

**风险 / 难点**：
- 涉及到状态管理（熔断、重试），容易出边界情况
- 需要注意不要在单个请求内「无限切换」引擎

---

## 阶段 6：Celery 异步任务队列接入（单任务异步）（难度：★★★★☆）

**目标**：将单个文件转换从同步请求改造为异步任务（调用 Celery），前端拿到 task_id 后用 status API 轮询。

### 任务
1. 引入 Celery 与 Redis
   - 在 `requirements.txt` 中增加：`celery`, `redis`, `flower`
   - 新建：
     - `app/services/queue/celery_app.py`（Celery 初始化）
     - 顶层 `celery_worker.py`（启动 worker 的入口）

2. 定义 Celery 任务
   - 文件：`app/services/queue/tasks.py`
   - 任务：`convert_pdf_to_markdown(file_path, options)`
   - 任务内部复用 `ConversionService`
   - 使用 `task.update_state(state='PROGRESS', meta=...)` 更新进度

3. 改造 /convert 接口为异步模式（新增而不替换原同步）
   - 新增：`POST /api/v1/convert/async`
     - 上传文件 → 保存 → 提交 Celery 任务 → 立即返回 `task_id`

4. 状态查询对接 Celery
   - 在 `status.py` 中：
     - 如果 `task_id` 来自 Celery，则通过 `AsyncResult` 查询状态
     - 返回统一格式：queued / processing / completed / failed

5. 并发参数配置
   - 在 `config.py` 中新增：
     - `CELERY_BROKER_URL`
     - `CELERY_RESULT_BACKEND`
     - `MAX_CONCURRENT_PDF_TASKS`（worker 并发）

**风险 / 难点**：
- 异步任务失败重试、超时等策略需要仔细设计
- Windows 上跑 Celery 和 Redis（开发环境）可能有坑，需要注意

---

## 阶段 7：批量上传 & 并发处理（难度：★★★★★）

**目标**：实现一次上传多文件，后端通过 Celery 并发处理，并提供批次级别的进度与结果查询。

### 任务
1. 批次数据模型与管理器
   - 新建：`app/services/conversion/batch_manager.py`
   - 模型：`BatchTask`
     - `batch_id`
     - `task_ids: list[str]`
     - `status: queued/processing/completed/partial_failed/failed`
     - `created_at/completed_at`

2. 批量上传 API
   - 文件：`app/api/v1/endpoints/batch.py`
   - 接口：`POST /api/v1/convert/batch`
     - files: `List[UploadFile]`
     - options: JSON
     - 限制：
       - 最大文件数（如 20）
       - 总大小限制
     - 行为：
       - 保存所有文件
       - 使用 Celery `group` 提交多个任务
       - 生成 `batch_id` 并记录所有子 `task_id`

3. 批次状态查询
   - 接口：`GET /api/v1/batch/status/{batch_id}`
   - 聚合所有子任务的状态：
     - 完成数、失败数、队列中数量
     - 计算整体进度百分比

4. 批量下载
   - 接口：`GET /api/v1/batch/download/{batch_id}`
   - 将所有成功任务的 Markdown 打包成 ZIP 并返回

5. 队列与资源控制
   - 控制：
     - Celery worker 并发数
     - 任务重试策略
     - 对同一批次任务的简单优先处理策略（可先不做复杂优先级队列）

**风险 / 难点**：
- 与 PRD 中多文件批量处理部分高度一致
- 需要小心控制内存、IO与第三方 OCR 限流
- 设计不当容易导致队列堆积和系统不稳定

---

## 阶段 8：并发测试、压测与优化（难度：★★★★★）

**目标**：验证在高并发和大批量文件场景下系统的稳定性，并针对瓶颈进行优化。

### 任务
1. 单元测试 & 集成测试
   - 为：
     - OCRRouter
     - Celery 任务
     - 批量上传与状态查询
   - 编写系统级测试：
     - 一次提交 20 个 PDF
     - 观察完成时间、失败率

2. 并发压测
   - 使用：
     - locust / k6 / 自写脚本
   - 压测场景：
     - 多客户端同时上传单文件
     - 多客户端同时上传批量任务

3. 性能优化
   - 根据监控和日志：
     - 调整 `MAX_CONCURRENT_PDF_TASKS`、`max_concurrent_api_calls`
     - 调整 Celery worker 数量和预取策略

4. 监控与告警（可先做简单日志统计）
   - 统计：
     - 任务成功率、失败率
     - 队列长度
     - 平均处理时间

**风险 / 难点**：
- 真正发现系统瓶颈的位置通常和预期不完全一致
- 需要一定时间反复调参与观察

---

## 总结：实施顺序总览（由易到难）

1. **阶段 0**：现有项目梳理与基础清理（★☆☆☆☆）
2. **阶段 1**：API 与目录结构规范化（★☆☆☆☆）
3. **阶段 2**：图片压缩 WebP API 封装（★★☆☆☆）
4. **阶段 3**：PDF→Markdown 现有功能增强（★★☆☆☆）
5. **阶段 4**：MinerU 接入与双引擎封装（★★★☆☆）
6. **阶段 5**：OCR 引擎轮询与负载均衡（★★★★☆）
7. **阶段 6**：Celery 单任务异步改造（★★★★☆）
8. **阶段 7**：批量上传 & 并发处理（★★★★★）
9. **阶段 8**：并发测试、压测与优化（★★★★★）

建议从阶段 0 开始逐步推进，每完成一个阶段在本文件中追加「实际实现记录」与「问题总结」，形成完整的技术文档闭环。